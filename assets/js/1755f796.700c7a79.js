"use strict";(self.webpackChunktestdoc=self.webpackChunktestdoc||[]).push([[5093],{28453:(e,r,n)=>{n.d(r,{R:()=>o,x:()=>i});var s=n(96540);const t={},a=s.createContext(t);function o(e){const r=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function i(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(a.Provider,{value:r},e.children)}},81352:(e,r,n)=>{n.d(r,{A:()=>s});const s=n.p+"assets/images/spark-memory-edca926bd29e5fd453e7d53120ad686b.png"},98725:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"big-data/Apache Spark/memory","title":"Memory","description":"Executor memory","source":"@site/docs/big-data/Apache Spark/memory.md","sourceDirName":"big-data/Apache Spark","slug":"/big-data/Apache Spark/memory","permalink":"/Docs/docs/next/big-data/Apache Spark/memory","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/big-data/Apache Spark/memory.md","tags":[],"version":"current","frontMatter":{},"sidebar":"bigdataSidebar","previous":{"title":"Shuffle and Join","permalink":"/Docs/docs/next/big-data/Apache Spark/join_shuffle"},"next":{"title":"pres","permalink":"/Docs/docs/next/big-data/Apache Spark/pres"}}');var t=n(74848),a=n(28453);const o={},i="Memory",c={},d=[{value:"Executor memory",id:"executor-memory",level:2},{value:"On-heap",id:"on-heap",level:3},{value:"Cache and Repartition",id:"cache-and-repartition",level:2}];function l(e){const r={h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"memory",children:"Memory"})}),"\n",(0,t.jsx)(r.h2,{id:"executor-memory",children:"Executor memory"}),"\n",(0,t.jsx)(r.h3,{id:"on-heap",children:"On-heap"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Spark Memory (spark.memory.fraction)"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Storage Memory (spark.memory.storageFraction) :"})," used to store Spark cache data, such as RDD cache, Broadcast variable, Unroll data (process of deserializing a serialized data), and so on."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Execution Memory:"}),"  used to store temporary data in the calculation process of Shuffle, Join, Sort, Aggregation, etc"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"User Memory:"})," It's mainly used to store the data needed for RDD conversion operations, such as the information for RDD dependency"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Reserved Memory (300MB):"})," The memory is reserved for system and is used to store Spark's internal objects"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Spark fail if we don't give executor memory at least 1.5 * Reveserved Memory = 450MB"}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.img,{alt:"memory",src:n(81352).A+"",width:"788",height:"749"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"cache-and-repartition",children:"Cache and Repartition"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Cache: use MEMORY_AND_DISK storage level."}),"\n",(0,t.jsx)(r.li,{children:"Persist: the storage level can be changed."}),"\n",(0,t.jsx)(r.li,{children:"Cache and persist are lazy operations (transformations)"}),"\n",(0,t.jsx)(r.li,{children:"Spark drops persisted data if not used or by using least-recently-used (LRU) algorithm."}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,a.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);