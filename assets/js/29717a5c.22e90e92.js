"use strict";(self.webpackChunktestdoc=self.webpackChunktestdoc||[]).push([[8512],{28453:(e,i,t)=>{t.d(i,{R:()=>o,x:()=>s});var n=t(96540);const a={},r=n.createContext(a);function o(e){const i=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function s(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),n.createElement(r.Provider,{value:i},e.children)}},83659:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"big-data/Apache Iceberg/optimization","title":"Optimization","description":"- Reducing the number of data files","source":"@site/docs/big-data/Apache Iceberg/optimization.md","sourceDirName":"big-data/Apache Iceberg","slug":"/big-data/Apache Iceberg/optimization","permalink":"/Docs/docs/next/big-data/Apache Iceberg/optimization","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/big-data/Apache Iceberg/optimization.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"bigdataSidebar","previous":{"title":"Apache Iceberg Architecture","permalink":"/Docs/docs/next/big-data/Apache Iceberg/architecture"},"next":{"title":"Reading and Writing in Apache Iceberg","permalink":"/Docs/docs/next/big-data/Apache Iceberg/read-write"}}');var a=t(74848),r=t(28453);const o={sidebar_position:2},s="Optimization",c={},l=[{value:"Compaction",id:"compaction",level:2},{value:"Partition",id:"partition",level:2}];function d(e){const i={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.header,{children:(0,a.jsx)(i.h1,{id:"optimization",children:"Optimization"})}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:"Reducing the number of data files"}),"\n",(0,a.jsx)(i.li,{children:"Data sorting"}),"\n",(0,a.jsx)(i.li,{children:"Table partitionning"}),"\n",(0,a.jsx)(i.li,{children:"Row-level update handling"}),"\n",(0,a.jsx)(i.li,{children:"Metric collection"}),"\n",(0,a.jsx)(i.li,{children:"External factors"}),"\n"]}),"\n",(0,a.jsx)(i.h2,{id:"compaction",children:"Compaction"}),"\n",(0,a.jsx)(i.p,{children:"Each operation on file genererate metadata file this can lead to small files problem, espcially when delaing with stream.\r\nThe solution is to periodically take the data in the all small files and rewrite it into a lager files (you may also want to rewrite manifests if there are too many manifests relative to the number of datafiles you have). This process is calle compation"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:"In Spark the compaction is performed using the method: reweriteDataFiles:"}),"\n",(0,a.jsxs)(i.li,{children:["Methods:","\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:"binPack"}),"\n",(0,a.jsx)(i.li,{children:"Sort"}),"\n",(0,a.jsx)(i.li,{children:"zOrder"}),"\n",(0,a.jsx)(i.li,{children:"filter"}),"\n",(0,a.jsx)(i.li,{children:"option"}),"\n",(0,a.jsx)(i.li,{children:"options"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(i.h2,{id:"partition",children:"Partition"}),"\n",(0,a.jsx)(i.p,{children:"When a table is partitioned, instead of just sorting the order based on a field, it will write records with distinct values of the target field into their own datafiles."})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);