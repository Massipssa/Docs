"use strict";(self.webpackChunktestdoc=self.webpackChunktestdoc||[]).push([[378],{28453:(e,n,a)=>{a.d(n,{R:()=>l,x:()=>d});var i=a(96540);const t={},s=i.createContext(t);function l(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(s.Provider,{value:n},e.children)}},84174:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>r,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"big-data/Fundamentals/Ingestion","title":"Data Ingestion","description":"Key concepts","source":"@site/docs/big-data/Fundamentals/Ingestion.md","sourceDirName":"big-data/Fundamentals","slug":"/big-data/Fundamentals/Ingestion","permalink":"/Docs/docs/next/big-data/Fundamentals/Ingestion","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/big-data/Fundamentals/Ingestion.md","tags":[],"version":"current","frontMatter":{},"sidebar":"bigdataSidebar","previous":{"title":"Apache Parquet","permalink":"/Docs/docs/next/big-data/File-formats/apache-parquet"},"next":{"title":"Data Architecture","permalink":"/Docs/docs/next/big-data/Fundamentals/architecture"}}');var t=a(74848),s=a(28453);const l={},d="Data Ingestion",r={},o=[{value:"Key concepts",id:"key-concepts",level:2},{value:"Syn and Async ingestion",id:"syn-and-async-ingestion",level:3},{value:"Synchronous Ingestion",id:"synchronous-ingestion",level:3},{value:"Asynchronous Ingestion",id:"asynchronous-ingestion",level:3},{value:"Serialization and Deserialization",id:"serialization-and-deserialization",level:3},{value:"Throughput and Scalability",id:"throughput-and-scalability",level:3},{value:"Reliability and Durability",id:"reliability-and-durability",level:3},{value:"Payload",id:"payload",level:3},{value:"Kind",id:"kind",level:3},{value:"Shape",id:"shape",level:3},{value:"Size",id:"size",level:3},{value:"Schema and data types",id:"schema-and-data-types",level:3},{value:"Schema Registry",id:"schema-registry",level:3},{value:"Matadata",id:"matadata",level:3},{value:"Pull and Push",id:"pull-and-push",level:2},{value:"Batch Ingestion",id:"batch-ingestion",level:2},{value:"Commong pattern",id:"commong-pattern",level:3}];function c(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"data-ingestion",children:"Data Ingestion"})}),"\n",(0,t.jsx)(n.h2,{id:"key-concepts",children:"Key concepts"}),"\n",(0,t.jsx)(n.h3,{id:"syn-and-async-ingestion",children:"Syn and Async ingestion"}),"\n",(0,t.jsx)(n.h3,{id:"synchronous-ingestion",children:"Synchronous Ingestion"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The donwstream process can't start until all data in the batch have been completly ingested. If any ingestion of transformation process fails, the entire process must be rereun."}),"\n",(0,t.jsx)(n.li,{children:"A --\x3e B --\x3e C"}),"\n",(0,t.jsx)(n.li,{children:"A, B, and C directly dependent upon one another"}),"\n",(0,t.jsx)(n.li,{children:"(A faills, B and C cannot start, if B fails the process C can't start)"}),"\n",(0,t.jsx)(n.li,{children:"Common in ETL where data extracted from source must be transformed before being loaded into dat awarehouse"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"asynchronous-ingestion",children:"Asynchronous Ingestion"}),"\n",(0,t.jsx)(n.p,{children:"With asynchronous ingestion, dependencies can now operate at the level of individual  events,  much  as  they  would  in  a  software  backend  built  from  microservices"}),"\n",(0,t.jsx)(n.h3,{id:"serialization-and-deserialization",children:"Serialization and Deserialization"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Serialization: encoding the data from a source and preparing data structures for transmission and intermediate storage stages."}),"\n",(0,t.jsx)(n.li,{children:"Deserialization:"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"throughput-and-scalability",children:"Throughput and Scalability"}),"\n",(0,t.jsx)(n.p,{children:"Ingestion boteleck are common in practice. Data throughput and system scalabilty become critical as data volume grow and requirtments change.\r\nCase where a database goes downn, and in backfill will your system be able to keep up with this sudden influx of backlogged data?\r\nThe system built-in buffering is  required  to  collect  events  during  rate  spikes  to  prevent  data  from  getting  lost"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Whenever possible uses managed service that handles the throughput scaling for you (can be accoplished manually but often isn't value-added and there's a good chance you'll miss something)"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"reliability-and-durability",children:"Reliability and Durability"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Reliability: high uptime and proper failover for ingestion system"}),"\n",(0,t.jsx)(n.li,{children:"Durability: data isn't lost or corrupted"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Some system may not retain data if it's not properly ingested. Thare require you to build an apporperite level of redendancy and self-healing based on the impact and cost of losing data.\r\nEvaluat the direct cost and indirect cost"}),"\n",(0,t.jsx)(n.h3,{id:"payload",children:"Payload"}),"\n",(0,t.jsx)(n.p,{children:"Is a dataset you're ingesting and it has many charactersitics"}),"\n",(0,t.jsx)(n.h3,{id:"kind",children:"Kind"}),"\n",(0,t.jsx)(n.p,{children:"It constists of type and format"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Type: tabular, video, text"}),"\n",(0,t.jsx)(n.li,{children:"Foamrt: the way the data is expressed in bytes, names, and file extensions."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"shape",children:"Shape"}),"\n",(0,t.jsx)(n.p,{children:"Describes the dimensions"}),"\n",(0,t.jsx)(n.h3,{id:"size",children:"Size"}),"\n",(0,t.jsx)(n.p,{children:"the number of bytes of the payload"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Can be compressed"}),"\n",(0,t.jsx)(n.li,{children:"Can be also split into chuncks"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"schema-and-data-types",children:"Schema and data types"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A schema  describes  the  fields  and  types  of  data within those fields"}),"\n",(0,t.jsxs)(n.li,{children:["Schema changes occurs often in upstream system they need to be cathced, some examples","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Adding column"}),"\n",(0,t.jsx)(n.li,{children:"Renaming column"}),"\n",(0,t.jsx)(n.li,{children:"Change column type"}),"\n",(0,t.jsx)(n.li,{children:"Creating table"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Implementing stragtegie that detect changes and altering the downstream pipelines is required to avoid breaks"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"schema-registry",children:"Schema Registry"}),"\n",(0,t.jsx)(n.p,{children:"A  schema  registry  is  a  metadata repository used to maintain schema and data type integrity in the face of constantly changing schemas for streaming data."}),"\n",(0,t.jsx)(n.h3,{id:"matadata",children:"Matadata"}),"\n",(0,t.jsx)(n.p,{children:"Metadata is data about data.\r\nMetadata  can  be  as  critical  as  the  data  itself."}),"\n",(0,t.jsx)(n.h2,{id:"pull-and-push",children:"Pull and Push"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A push strategy involves a source system sending data to a target"}),"\n",(0,t.jsxs)(n.li,{children:["Pull strategy entails a target reading data directly from a source","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Polling  involves periodically checking a data source for any changes. When changes are detected, the destination pulls the data as it would in a regular pull situation."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"batch-ingestion",children:"Batch Ingestion"}),"\n",(0,t.jsx)(n.p,{children:"Ingest data in bulck"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Time-interval batch ingestion"}),"\n",(0,t.jsx)(n.li,{children:"Size-based batch ingestion"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"commong-pattern",children:"Commong pattern"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Snapshot or Diff erential Extraction: to  capture  full  snapshots  of  a  source  system or differential (sometimes called incremental) updates"}),"\n",(0,t.jsx)(n.li,{children:"File-Based Export and Ingestion: data prepared and packaged in source system and then send to destinatin via common file-exhange method like object storage, Secure File Transfer Transport (SFTP), Secur Copy (SCP), Electoric Data Interchange (EDI)."}),"\n",(0,t.jsx)(n.li,{children:"ETL vs ELT"}),"\n",(0,t.jsx)(n.li,{children:"Inserts, Updates, and Batch Size"}),"\n",(0,t.jsx)(n.li,{children:"Data Migration"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);