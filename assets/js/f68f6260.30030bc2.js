"use strict";(self.webpackChunktestdoc=self.webpackChunktestdoc||[]).push([[1923],{28453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var r=s(96540);const i={},a=r.createContext(i);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:n},e.children)}},90932:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"big-data/Apache Spark/pres","title":"pres","description":"Why Spark ?","source":"@site/versioned_docs/version-1.0/big-data/Apache Spark/pres.md","sourceDirName":"big-data/Apache Spark","slug":"/big-data/Apache Spark/pres","permalink":"/Docs/docs/big-data/Apache Spark/pres","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/versioned_docs/version-1.0/big-data/Apache Spark/pres.md","tags":[],"version":"1.0","frontMatter":{},"sidebar":"bigdataSidebar","previous":{"title":"Memory","permalink":"/Docs/docs/big-data/Apache Spark/memory"},"next":{"title":"structuredStream","permalink":"/Docs/docs/big-data/Apache Spark/structuredStream"}}');var i=s(74848),a=s(28453);const t={},l=void 0,o={},d=[{value:"<strong>Why Spark ?</strong>",id:"why-spark-",level:2},{value:"<strong>Spark architecture</strong>",id:"spark-architecture",level:2},{value:"How can be executed a Spark App <strong>Execution modes</strong>",id:"how-can-be-executed-a-spark-app-execution-modes",level:2},{value:"Deploy modes",id:"deploy-modes",level:2},{value:"Transformation vs action",id:"transformation-vs-action",level:2},{value:"<strong>How does Spark partition the data ?</strong>  <strong>===&gt; add an image</strong>",id:"how-does-spark-partition-the-data----add-an-image",level:2},{value:"Spark memory types ? <strong>Add image</strong>",id:"spark-memory-types--add-image",level:2},{value:"Notion of APP -&gt; Stage -&gt; tasks (vcore)",id:"notion-of-app---stage---tasks-vcore",level:2},{value:"How handales data recovery <strong>==&gt;Add an image</strong>",id:"how-handales-data-recovery-add-an-image",level:2},{value:"To present later",id:"to-present-later",level:2}];function c(e){const n={code:"code",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"why-spark-",children:(0,i.jsx)(n.strong,{children:"Why Spark ?"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["In-memory Computation (100x times faster than MR in memory, 10x faster than on disk) ",(0,i.jsx)(n.strong,{children:"===> Remark DS"})]}),"\n",(0,i.jsxs)(n.li,{children:["Resilient Distributed Datasets (RDD)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Immuatable (Why ?) ",(0,i.jsx)(n.strong,{children:"Because of fact that data is distruted + servers in data recovery"})]}),"\n",(0,i.jsx)(n.li,{children:"Can be cached or persisted"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Lazy Evaluation"}),"\n",(0,i.jsx)(n.li,{children:"Batch and stream processing"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"spark-architecture",children:(0,i.jsx)(n.strong,{children:"Spark architecture"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Driver"}),"\n",(0,i.jsx)(n.li,{children:"Executors"}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"how-can-be-executed-a-spark-app-execution-modes",children:["How can be executed a Spark App ",(0,i.jsx)(n.strong,{children:"Execution modes"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Standalone (local)"}),"\n",(0,i.jsx)(n.li,{children:"Yarn"}),"\n",(0,i.jsx)(n.li,{children:"Kubernetes"}),"\n",(0,i.jsx)(n.li,{children:"Mesos"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"deploy-modes",children:"Deploy modes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Client"}),"\n",(0,i.jsx)(n.li,{children:"Cluster (main difference: owner of resources ??)"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"transformation-vs-action",children:"Transformation vs action"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Transformation always returns an RDD (wide and large --\x3e add schema)"}),"\n",(0,i.jsx)(n.li,{children:"Action"}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"how-does-spark-partition-the-data----add-an-image",children:[(0,i.jsx)(n.strong,{children:"How does Spark partition the data ?"}),"  ",(0,i.jsx)(n.strong,{children:"===> add an image"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Huge amount of data can't fit in one single node memory"}),"\n",(0,i.jsx)(n.li,{children:"Leads to minimize IO (serialization and deserialization)"}),"\n",(0,i.jsxs)(n.li,{children:["Spark uses the princpe of data locality (read date from the nodes that are close) ",(0,i.jsx)(n.strong,{children:"look in detail"})]}),"\n",(0,i.jsxs)(n.li,{children:["Creates a partition of size 128 MB in HDFS","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The partition itself can be partited by HDFS (in hdfs way)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Imagine it as a file that you write and every file writen to HDFS is partitionned"}),"\n",(0,i.jsx)(n.li,{children:"Partiton of 256 MB => 2 blocks in HDFS (HDFS partition)"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Having many partitions doesn't mean more performance","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Partition task, so, many partitions will the increase the execution time because it\r\nrequires a lot of time for creating, scheduling and manging task by spark scheduler"}),"\n",(0,i.jsx)(n.li,{children:"A lot of partition leads to huge flow between driver and executor (Increase IO. Well known Small files issue in HDFS that saturates INodes tables)"}),"\n",(0,i.jsx)(n.li,{children:"Empty partitions take time to compute"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["A few number of partition","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Idle nodes"}),"\n",(0,i.jsx)(n.li,{children:"Data skew issue"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Recommandation:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"2x or 3x number of vcores"}),"\n",(0,i.jsxs)(n.li,{children:["100 ms to computes a partition ",(0,i.jsx)(n.strong,{children:"(benchmark have been done on machines with average capacities)"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Example:  file of 10KB in 20 partitions"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'  read.text("path/to/text.txt")\r\n      .repartition(20)\n'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"repartition() or coalesce(): partition data in memory"}),"\n",(0,i.jsx)(n.li,{children:"partitionBy(): partition data in disk"}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"spark-memory-types--add-image",children:["Spark memory types ? ",(0,i.jsx)(n.strong,{children:"Add image"})]}),"\n",(0,i.jsx)(n.h2,{id:"notion-of-app---stage---tasks-vcore",children:"Notion of APP -> Stage -> tasks (vcore)"}),"\n",(0,i.jsxs)(n.h2,{id:"how-handales-data-recovery-add-an-image",children:["How handales data recovery ",(0,i.jsx)(n.strong,{children:"==>Add an image"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Node crash (no heartbeat are received from the node) ??"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Lineage graph (execution plan) --\x3e  DAG"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Applies the same execution plan in all nodes leads to recover the data"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Task fails ?"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Retry"}),"\n",(0,i.jsx)(n.li,{children:"It no ==> assign to new executor"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"How spark reads config ? Order is important"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Main"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'SparkSession spark = SparkSession\r\n      .master("local")\r\n      .config("key1", "value1")\r\n      ...\r\n      .getOrCreate() // Important ? \n'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Spark-submit"}),"\n",(0,i.jsx)(n.li,{children:"Default config"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"to-present-later",children:"To present later"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Spark plans"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);