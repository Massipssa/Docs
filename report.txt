import software.amazon.awssdk.services.s3.S3Client
import software.amazon.awssdk.services.s3.model.GetObjectRequest
import software.amazon.awssdk.core.sync.RequestBody
import software.amazon.awssdk.services.s3.model.PutObjectRequest
import org.apache.commons.compress.archivers.tar._
import java.io._
import scala.collection.parallel.CollectionConverters._

val s3Client = S3Client.builder().build()

// Function to stream and extract tar file
def extractTar(bucket: String, tarKey: String): List[(String, Array[Byte])] = {
  val request = GetObjectRequest.builder().bucket(bucket).key(tarKey).build()
  val s3Stream = s3Client.getObject(request) // Returns an InputStream
  
  val tarArchive = new TarArchiveInputStream(new BufferedInputStream(s3Stream))

  Iterator.continually(tarArchive.getNextTarEntry)
    .takeWhile(_ != null)
    .filter(!_.isDirectory)
    .map { entry =>
      val byteArray = new ByteArrayOutputStream()
      val buffer = new Array   // 8 KB       var bytesRead = tarArchive.read(buffer)
      while (bytesRead != -1) {
        byteArray.write(buffer, 0, bytesRead)
        bytesRead = tarArchive.read(buffer)
      }
      (entry.getName, byteArray.toByteArray)
    }
    .toList
}

// Function to upload extracted files to S3 in parallel
def uploadToS3(file: (String, Array[Byte])): Unit = {
  val (fileName, content) = file
  val uploadRequest = PutObjectRequest.builder()
    .bucket("your-bucket")
    .key(s"untarred/$fileName")
    .build()
  
  s3Client.putObject(uploadRequest, RequestBody.fromBytes(content))
}

// S3 Bucket & Tar File Path
val bucketName = "your-bucket"
val tarFileKey = "path/to/your_tar_file.tar"

// Extract files from tar
val extractedFiles = extractTar(bucketName, tarFileKey)

// Convert to Parallel Collection and Upload in Parallel
extractedFiles.par.foreach(uploadToS3)

println(s"Successfully processed ${extractedFiles.length} files in parallel!")
