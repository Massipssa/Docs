import org.apache.spark.sql.functions._

// Ajouter une colonne "cNumber" qui correspond à `_c(position-1)`
val metadataWithColumnDf = metadataWithConfigDf
  .withColumn("cNumber", concat(lit("_c"), (col("position") - 1).cast("string")))

// Vérifier que la colonne `_cNumber` existe bien dans `dataFileDf`
val validColumns = dataFileDf.columns.toSet
val filteredMetadataDf = metadataWithColumnDf.filter(col("cNumber").isin(validColumns.toSeq: _*))


// Appliquer la validation avec rlike
var checkedDf = dataFileDf
filteredMetadataDf.collect().foreach { row =>
  val columnName = row.getAs[String]("cNumber")  // Ex: "_c12"
  val regex = row.getAs[org.apache.spark.sql.Row]("config").getAs[String]("regex")

  checkedDf = checkedDf.withColumn(
    s"${columnName}_check",
    when(col(columnName).rlike(regex), lit("Valide"))
      .otherwise(lit(s"Format invalide"))
  )
}

// Afficher les résultats
checkedDf.show(false)
