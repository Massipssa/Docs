import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("Compare with First Row")
  .master("local[*]")  // Remplace par le mode cluster si nécessaire
  .getOrCreate()

import spark.implicits._

// 📌 1️⃣ Création du DataFrame avec des colonnes _c0 à _c6
val df = Seq(
  ("A", "X", "1", "P", "Red", "100", "Yes"),  // 🔹 Référence (1ère ligne)
  ("A", "X", "2", "Q", "Blue", "200", "No"),  // ❌ Différences dans _c2, _c3, _c4, _c5, _c6
  ("A", "Y", "1", "P", "Red", "100", "Yes"),  // ❌ Différence dans _c1
  ("C", "Z", "3", "P", "Red", "100", "Yes"),  // ❌ Différences dans _c0, _c1, _c2
  ("A", "X", "1", "P", "Red", "100", "Yes")   // ✅ Identique à la 1ère ligne
).toDF("_c0", "_c1", "_c2", "_c3", "_c4", "_c5", "_c6")

// 📌 2️⃣ Appliquer `first()` sur chaque colonne pour récupérer la première valeur
val firstValuesDf = df.select(df.columns.map(c => first(col(c)).over() as s"${c}_first"): _*)

// 📌 3️⃣ Ajouter une colonne indiquant si la ligne est différente de la première
val dfWithFirstValues = df.withColumns(
  df.columns.map(c => s"${c}_diff" -> (col(c) =!= first(col(c)).over()))
)

// 📌 4️⃣ Filtrer les lignes où au moins une colonne est différente
val diffDf = dfWithFirstValues.filter(
  df.columns.map(c => col(s"${c}_diff")).reduce(_ || _)
).select(df.columns.map(col): _*) // On garde uniquement les colonnes originales

// 📌 5️⃣ Afficher les lignes qui diffèrent de la première ligne
diffDf.show(false)
