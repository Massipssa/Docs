import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("Check Multiple Columns Uniformity")
  .master("local[*]") // Pour exécution locale
  .getOrCreate()

import spark.implicits._

// Générer dynamiquement la liste des colonnes de c0 à c6
val columns = (0 to 6).map(i => s"c$i").toList

// Exemple de DataFrame avec les colonnes c0 à c6
val data = Seq(
  (1, "A", "X", 100, 10.5, "2024-02-19", "Yes"),
  (1, "A", "Y", 100, 10.5, "2024-02-19", "Yes"),  // Différence dans c2
  (1, "A", "X", 100, 10.5, "2024-02-19", "Yes")
).toDF(columns: _*)

// Vérifier l'uniformité avec countDistinct()
val checkUniformity = data.agg(
  columns.map(c => countDistinct(col(c)).as(s"unique_$c")): _*
)

// Ajouter des colonnes booléennes pour indiquer l’uniformité
val result = columns.foldLeft(checkUniformity) { (df, colName) =>
  df.withColumn(s"${colName}_uniform", col(s"unique_$colName") === 1)
}

// Récupérer les index des colonnes où les valeurs sont différentes (non uniformes)
val nonUniformColumns = result.collect().flatMap { row =>
  columns.zipWithIndex.collect {
    case (colName, idx) if row.getAs[Long](s"unique_$colName") > 1 => idx
  }
}

// Afficher le résultat
result.show()

// Afficher la liste des index des colonnes non uniformes
println(s"Colonnes non uniformes (index) : ${nonUniformColumns.mkString(", ")}")
