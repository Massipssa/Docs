import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.UserDefinedFunction

// UDF pour valider le format d'une colonne
def validateFormatUDF(regex: String): UserDefinedFunction = udf((value: String) => {
  if (value == null || value.matches(regex)) None else Some(s"Format invalide : $value")
})

// Fonction pour appliquer les règles de validation sans utiliser `var`
def applyValidation(dataFileDf: DataFrame, metadataWithConfigDf: DataFrame): DataFrame = {
  metadataWithConfigDf
    .filter(col("config").isNotNull) // Filtrer les familles qui ont une config
    .collect()
    .foldLeft(dataFileDf) { (df, row) =>
      val columnName = row.getAs[String]("colonne")
      val regex = row.getAs[FamilleFormatConfigLineDto]("config").regex
      df.withColumn(s"${columnName}_check", validateFormatUDF(regex)(col(columnName)))
    }
}

// Appliquer les validations sur le DataFrame
val checkedDf = applyValidation(dataFileDf, metadataWithConfigDf)

// Afficher le résultat
checkedDf.show(false)
