import com.amazonaws.services.s3.AmazonS3
import com.amazonaws.services.s3.model._

import java.io._
import java.nio.charset.StandardCharsets
import java.nio.file.{Files, Path}
import scala.util.control.NonFatal

trait S3Service {
  def put(bucket: String, key: String, content: String, contentType: String): Unit
  def put(bucket: String, destKey: String, inputStream: InputStream, uploadPartSize: Int): Unit
}

trait Logging {
  protected def logInfo(msg: String): Unit = println(s"[INFO] $msg")
  protected def logWarn(msg: String): Unit = println(s"[WARN] $msg")
  protected def logError(msg: String): Unit = println(s"[ERROR] $msg")
}

class DefaultS3Service(val s3Client: AmazonS3) extends S3Service with Logging {

  private val MinPartSize: Int = 5 * 1024 * 1024 // 5MB (règle S3 multipart)

  // ---------------------------------------------------------------------------
  // 1) put string (comme ton screenshot)
  // ---------------------------------------------------------------------------
  override def put(bucket: String, key: String, content: String, contentType: String): Unit = {
    val bytes = content.getBytes(StandardCharsets.UTF_8)
    val md = new ObjectMetadata()
    md.setContentType(contentType)
    md.setContentLength(bytes.length.toLong)

    val is = new ByteArrayInputStream(bytes)
    try {
      s3Client.putObject(bucket, key, is, md)
      logInfo(s"PutObject OK: s3://$bucket/$key (bytes=${bytes.length})")
    } finally {
      safeClose(is)
    }
  }

  // ---------------------------------------------------------------------------
  // 2) put inputStream multipart automatique (SIGNATURE IDENTIQUE SCREENSHOT)
  //    - si stream < 5MB => putObject
  //    - sinon => multipart
  //    - corrige le bug "arrêt à 5MB" via readFully()
  // ---------------------------------------------------------------------------
  override def put(bucket: String, destKey: String, inputStream: InputStream, uploadPartSize: Int): Unit = {
    val partSize = math.max(uploadPartSize, MinPartSize)

    // 1) Sniff: lire jusqu’à 5MB pour savoir si c’est petit ou gros (sans threshold à fournir)
    val sniff = readUpTo(inputStream, MinPartSize)

    if (sniff.isEmpty) {
      // stream vide => objet vide
      putBytes(bucket, destKey, Array.emptyByteArray, "application/octet-stream")
      safeClose(inputStream)
      return
    }

    if (sniff.length < MinPartSize) {
      // petit => putObject (safe: <=5MB en RAM)
      putBytes(bucket, destKey, sniff, "application/octet-stream")
      safeClose(inputStream)
      return
    }

    // 2) Gros stream => multipart
    // on "rejoue" le sniff au début du stream grâce à un stream chaîné
    val chained = new SequenceInputStream(new ByteArrayInputStream(sniff), inputStream)

    try {
      multipartUpload(bucket, destKey, chained, contentType = "application/octet-stream", partSizeBytes = partSize)
    } finally {
      safeClose(chained) // ferme aussi inputStream
    }
  }

  // ---------------------------------------------------------------------------
  // Helpers putObject
  // ---------------------------------------------------------------------------
  private def putBytes(bucket: String, key: String, bytes: Array[Byte], contentType: String): Unit = {
    val md = new ObjectMetadata()
    md.setContentType(contentType)
    md.setContentLength(bytes.length.toLong)

    val is = new ByteArrayInputStream(bytes)
    try {
      s3Client.putObject(bucket, key, is, md)
      logInfo(s"PutObject OK: s3://$bucket/$key (bytes=${bytes.length})")
    } finally {
      safeClose(is)
    }
  }

  private def putStream(bucket: String, key: String, is: InputStream, length: Long, contentType: String): Unit = {
    val md = new ObjectMetadata()
    md.setContentType(contentType)
    md.setContentLength(length)
    s3Client.putObject(bucket, key, is, md)
    logInfo(s"PutObject OK: s3://$bucket/$key (length=$length)")
  }

  // ---------------------------------------------------------------------------
  // Multipart upload robuste
  //  - utilise readFully => évite parts < 5MB (sauf dernier)
  //  - eTags: java.util.ArrayList[PartETag] + add(new PartETag(...))
  //  - abort en cas d’erreur
  // ---------------------------------------------------------------------------
  private def multipartUpload(bucket: String, key: String, in: InputStream, contentType: String, partSizeBytes: Int): Unit = {
    val partSize = math.max(partSizeBytes, MinPartSize)

    val md = new ObjectMetadata()
    md.setContentType(contentType)

    val init = s3Client.initiateMultipartUpload(
      new InitiateMultipartUploadRequest(bucket, key).withObjectMetadata(md)
    )
    val uploadId = init.getUploadId

    val eTags = new java.util.ArrayList[PartETag]()
    val buffer = new Array[Byte](partSize)

    var partNumber = 1

    try {
      var bytesRead = readFully(in, buffer)

      // Stream vide (au cas où)
      if (bytesRead == 0) {
        s3Client.abortMultipartUpload(new AbortMultipartUploadRequest(bucket, key, uploadId))
        putBytes(bucket, key, Array.emptyByteArray, contentType)
        return
      }

      while (bytesRead > 0) {
        val partStream = new ByteArrayInputStream(buffer, 0, bytesRead)

        val req = new UploadPartRequest()
          .withBucketName(bucket)
          .withKey(key)
          .withUploadId(uploadId)
          .withPartNumber(partNumber)
          .withPartSize(bytesRead.toLong)
          .withInputStream(partStream)

        val res = s3Client.uploadPart(req)
        val etag = res.getETag
        if (etag == null) throw new IllegalStateException(s"Missing ETag for part=$partNumber s3://$bucket/$key uploadId=$uploadId")

        // ✅ Correct: on ajoute un PartETag, pas la String etag
        eTags.add(new PartETag(partNumber, etag))

        partNumber += 1
        bytesRead = readFully(in, buffer) // ✅ clé: pas in.read(buffer)
      }

      if (eTags.isEmpty) {
        throw new IllegalStateException(s"No parts uploaded for s3://$bucket/$key uploadId=$uploadId")
      }

      s3Client.completeMultipartUpload(new CompleteMultipartUploadRequest(bucket, key, uploadId, eTags))
      logInfo(s"Multipart upload OK: s3://$bucket/$key parts=${eTags.size()} uploadId=$uploadId")

    } catch {
      case NonFatal(e) =>
        logError(s"Multipart upload FAILED => abort: s3://$bucket/$key uploadId=$uploadId reason=${e.getMessage}")
        try s3Client.abortMultipartUpload(new AbortMultipartUploadRequest(bucket, key, uploadId))
        catch { case NonFatal(abortErr) => logWarn(s"Abort failed: ${abortErr.getMessage}") }
        throw e
    }
  }

  // ---------------------------------------------------------------------------
  // Utils lecture (IMPORTANT)
  // ---------------------------------------------------------------------------

  /** Lit jusqu’à remplir buffer ou EOF. Retourne 0 si EOF immédiat. */
  private def readFully(in: InputStream, buffer: Array[Byte]): Int = {
    var offset = 0
    var n = 0
    while (offset < buffer.length && { n = in.read(buffer, offset, buffer.length - offset); n != -1 }) {
      offset += n
    }
    offset
  }

  /** Lit au plus max bytes (peut retourner < max si EOF) */
  private def readUpTo(in: InputStream, max: Int): Array[Byte] = {
    val out = new ByteArrayOutputStream(math.min(max, 64 * 1024))
    val buf = new Array[Byte](64 * 1024)
    var remaining = max
    while (remaining > 0) {
      val n = in.read(buf, 0, math.min(buf.length, remaining))
      if (n == -1) return out.toByteArray
      out.write(buf, 0, n)
      remaining -= n
    }
    out.toByteArray
  }

  private def safeClose(c: Closeable): Unit =
    try c.close() catch { case _: Throwable => () }
}
