import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("Check Multiple Columns Uniformity")
  .master("local[*]") // Exécution locale
  .getOrCreate()

import spark.implicits._

// Générer dynamiquement la liste des colonnes c0 à c6
val columns = (0 to 6).map(i => s"c$i").toList

// Exemple de DataFrame avec les colonnes c0 à c6
val data = Seq(
  (1, "A", "X", 100, 10.5, "2024-02-19", "Yes"),
  (1, "A", "Y", 100, 10.5, "2024-02-19", "Yes"),  // Différence dans c2
  (1, "A", "X", 100, 10.5, "2024-02-19", "Yes")
).toDF(columns: _*)

// Vérifier l'uniformité avec countDistinct()
val countDistinctExprs = columns.map(c => countDistinct(col(c)).as(s"unique_$c"))

// Appliquer `countDistinct` aux colonnes sélectionnées
val checkUniformity = data.agg(countDistinctExprs.head, countDistinctExprs.tail: _*)

// Ajouter des colonnes booléennes pour indiquer l’uniformité
val result = columns.foldLeft(checkUniformity) { (df, colName) =>
  df.withColumn(s"${colName}_uniform", col(s"unique_$colName") === 1)
}

// Afficher le résultat final
result.show()

// Récupérer les index des colonnes non uniformes
val nonUniformColumns = result.head().toSeq
  .zipWithIndex
  .collect { case (v: Long, idx) if v > 1 => idx }

// Afficher la liste des index des colonnes non uniformes
println(s"Colonnes non uniformes (index) : ${nonUniformColumns.mkString(", ")}")
