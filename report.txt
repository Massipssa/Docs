import org.scalatest.funsuite.AnyFunSuite
import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.types._
import org.apache.spark.sql.functions._
import your.package.path.NumberOfColumnsToInterfaceEqualityCheck
import your.package.path.CreCsvFilenameDto
import your.package.path.CheckErrorDto

class NumberOfColumnsToInterfaceEqualityCheckTest extends AnyFunSuite {

  val spark: SparkSession = SparkSession.builder()
    .appName("TestSession")
    .master("local[*]")
    .getOrCreate()

  import spark.implicits._

  // Case class to simulate your DTO
  case class CreCsvFilenameDto(creId: String)

  test("should return empty list when column counts match") {
    val dataDF = Seq(
      ("val1", "val2", "val3")
    ).toDF("col1", "col2", "col3")

    // Create nested structure: interface.structureInterface = Array("col1", "col2")
    val metadataSchema = StructType(Seq(
      StructField("creId", StringType, nullable = false),
      StructField("interface", StructType(Seq(
        StructField("structureInterface", ArrayType(StringType, containsNull = false), nullable = false)
      )), nullable = false)
    ))

    val metadataRow = Row("cre123", Row(Array("col1", "col2")))
    val metadataDF = spark.createDataFrame(
      spark.sparkContext.parallelize(Seq(metadataRow)),
      metadataSchema
    )

    val creDto = CreCsvFilenameDto("cre123")

    val result = NumberOfColumnsToInterfaceEqualityCheck.check(dataDF, metadataDF, creDto)(spark)

    assert(result.isEmpty)
  }

  test("should return CheckErrorDto when column counts mismatch") {
    val dataDF = Seq(
      ("val1", "val2", "val3", "extra")
    ).toDF("col1", "col2", "col3", "extraCol")

    val metadataSchema = StructType(Seq(
      StructField("creId", StringType, nullable = false),
      StructField("interface", StructType(Seq(
        StructField("structureInterface", ArrayType(StringType, containsNull = false), nullable = false)
      )), nullable = false)
    ))

    val metadataRow = Row("cre123", Row(Array("col1", "col2", "col3")))
    val metadataDF = spark.createDataFrame(
      spark.sparkContext.parallelize(Seq(metadataRow)),
      metadataSchema
    )

    val creDto = CreCsvFilenameDto("cre123")

    val result = NumberOfColumnsToInterfaceEqualityCheck.check(dataDF, metadataDF, creDto)(spark)

    assert(result.nonEmpty)
    assert(result.head.getMessage.contains("Expected number of columns"))
  }
}
