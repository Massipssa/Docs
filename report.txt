import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("Compare with First Row")
  .master("local[*]")  // Remplace par le mode cluster si nÃ©cessaire
  .getOrCreate()

import spark.implicits._

// ğŸ“Œ 1ï¸âƒ£ CrÃ©ation du DataFrame avec des colonnes _c0 Ã  _c6
val df = Seq(
  ("A", "X", "1", "P", "Red", "100", "Yes"),  // ğŸ”¹ RÃ©fÃ©rence (1Ã¨re ligne)
  ("A", "X", "2", "Q", "Blue", "200", "No"),  // âŒ DiffÃ©rences dans _c2, _c3, _c4, _c5, _c6
  ("A", "Y", "1", "P", "Red", "100", "Yes"),  // âŒ DiffÃ©rence dans _c1
  ("C", "Z", "3", "P", "Red", "100", "Yes"),  // âŒ DiffÃ©rences dans _c0, _c1, _c2
  ("A", "X", "1", "P", "Red", "100", "Yes")   // âœ… Identique Ã  la 1Ã¨re ligne
).toDF("_c0", "_c1", "_c2", "_c3", "_c4", "_c5", "_c6")

// ğŸ“Œ 2ï¸âƒ£ Appliquer `first()` sur chaque colonne pour rÃ©cupÃ©rer la premiÃ¨re valeur
val firstValuesExprs = df.columns.map(c => first(col(c)).over() as s"${c}_first")

// ğŸ“Œ 3ï¸âƒ£ SÃ©lectionner toutes les colonnes originales + leurs valeurs de rÃ©fÃ©rence
val dfWithFirstValues = df.select(
  df.columns.map(col) ++ firstValuesExprs: _*
)

// ğŸ“Œ 4ï¸âƒ£ Comparer chaque colonne avec sa premiÃ¨re valeur
val diffCondition = df.columns.map(c => col(c) =!= col(s"${c}_first")).reduce(_ || _)

// ğŸ“Œ 5ï¸âƒ£ Filtrer uniquement les lignes diffÃ©rentes de la premiÃ¨re
val diffDf = dfWithFirstValues.filter(diffCondition).select(df.columns.map(col): _*)

// ğŸ“Œ 6ï¸âƒ£ Afficher les lignes qui diffÃ¨rent de la premiÃ¨re ligne
diffDf.show(false)
