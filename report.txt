import org.apache.spark.sql.{DataFrame, SparkSession, DataFrameWriterV2}
import org.apache.spark.sql.functions._

object WriterUtil {

  private def applyTableProperties(
      w: DataFrameWriterV2,
      props: Map[String, String]
  ): DataFrameWriterV2 =
    props.foldLeft(w) { case (acc, (k, v)) => acc.tableProperty(k, v) }

  def writeDaily(spark: SparkSession, fullTableName: String, df: DataFrame, props: Map[String, String]): Unit = {
    import spark.implicits._

    val df2 = df.withColumn("event_date", to_date(col("event_date")))

    val baseWriter: DataFrameWriterV2 = df2.writeTo(fullTableName)

    applyTableProperties(baseWriter, props)
      .partitionedBy(days($"event_date"))   // âœ… Column transform (spark.sql.functions.days)
      .createOrReplace()
  }
}
