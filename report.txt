import org.scalatest.funsuite.AnyFunSuite
import org.apache.spark.sql.{SparkSession, Row}
import fr.ccf.job.integration.checks.monitoring.DataStructureCheck
import java.nio.file.Files

class DataStructureCheckTest extends AnyFunSuite {

  val spark: SparkSession = SparkSession.builder()
    .appName("DataStructureCheckTest")
    .master("local[*]")
    .getOrCreate()

  test("check should return Left(DataFrame) when data is valid and not empty") {
    val jsonLine =
      """{"value": "{\"CRE\": \"ABCD\", \"nbLigne\": 10, \"dateTraitement\": \"2024-05-01\", \"vacation\": \"day\"}"}"""

    val file = Files.createTempFile("monitoring", ".json")
    Files.write(file, jsonLine.getBytes)

    val result = DataStructureCheck.check(file.toString)(spark)

    assert(result.isLeft)
    val df = result.left.get
    assert(df.count() == 1)
    assert(df.columns.contains("CRE"))
    assert(df.columns.contains("nbLigne"))
  }

  test("check should return Right(errorDto) when data is empty") {
    val file = Files.createTempFile("monitoring_empty", ".json")
    Files.write(file, Array.emptyByteArray)

    val result = DataStructureCheck.check(file.toString)(spark)

    assert(result.isRight)
    val error = result.right.get
    assert(error.isDefined)
    assert(error.get.message.contains("Could not parse all monitoringData lines"))
  }
}
