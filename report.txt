import boto3
import re

s3 = boto3.client('s3')

# Set this to your target prefix and bucket
SOURCE_BUCKET = 'my-bucket'
SOURCE_PREFIX = 'processed/'  # the folder where files are located

def lambda_handler(event, context):
    response = s3.list_objects_v2(Bucket=SOURCE_BUCKET, Prefix=SOURCE_PREFIX)

    if 'Contents' not in response:
        print("No files found.")
        return {'statusCode': 404, 'body': 'No files found'}

    for obj in response['Contents']:
        src_key = obj['Key']
        filename = src_key.split('/')[-1]  # e.g. 20221209_processed_files.csv

        match = re.match(r'(\d{4})(\d{2})(\d{2})_processed_files\.csv', filename)
        if not match:
            print(f"Skipping invalid file: {filename}")
            continue

        year, month, day = match.groups()
        dest_key = f'year={year}/month={month}/day={day}/processed_files.csv'

        print(f"Copying {src_key} â†’ {dest_key}")

        s3.copy_object(
            Bucket=SOURCE_BUCKET,
            CopySource={'Bucket': SOURCE_BUCKET, 'Key': src_key},
            Key=dest_key
        )

    return {
        'statusCode': 200,
        'body': 'All matching files copied successfully'
    }
