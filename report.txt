import org.apache.spark.sql.SparkSession
import org.apache.iceberg.Table
import org.apache.iceberg.spark.Spark3Util

import scala.jdk.CollectionConverters._

final case class ColDef(name: String, dataType: String)
final case class IcebergTableInfo(table: String, location: String, columns: List[ColDef])

def icebergTableInfo(fullTableName: String)(implicit spark: SparkSession): IcebergTableInfo = {
  val table: Table = Spark3Util.loadIcebergTable(spark, fullTableName)

  val cols: List[ColDef] =
    table.schema().columns().asScala
      .map(c => ColDef(c.name(), c.`type`().toString))
      .toList

  // location de la table (base location / data location)
  val loc: String =
    Option(table.location())
      .orElse(Option(table.properties().get("location")))
      .getOrElse("UNKNOWN")

  IcebergTableInfo(fullTableName, loc, cols)
}

// Usage
implicit val spark: SparkSession = SparkSession.builder().getOrCreate()

val info = icebergTableInfo("db.ma_table") // ou fullTableName
println(s"Location: ${info.location}")
info.columns.foreach(println)
