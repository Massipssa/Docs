import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("Check Multiple Columns Uniformity")
  .master("local[*]") // Pour exécution locale
  .getOrCreate()

import spark.implicits._

// Générer dynamiquement la liste des colonnes c0 à c6
val columns = (0 to 6).map(i => s"c$i").toList

// Exemple de DataFrame avec les colonnes c0 à c6
val data = Seq(
  (1, "A", "X", 100, 10.5, "2024-02-19", "Yes"),
  (1, "A", "Y", 100, 10.5, "2024-02-19", "Yes"),  // Différence dans c2
  (1, "A", "X", 100, 10.5, "2024-02-19", "Yes")
).toDF(columns: _*)

// Vérifier l'uniformité avec countDistinct()
val checkUniformity = data.agg(
  columns.map(c => countDistinct(col(c)).cast("long").as(s"unique_$c")): _*
)

// Ajouter des colonnes booléennes pour indiquer l’uniformité
val result = columns.foldLeft(checkUniformity) { (df, colName) =>
  df.withColumn(s"${colName}_uniform", col(s"unique_$colName") === 1)
}

// Afficher le résultat final
result.show()

// Récupérer les index des colonnes non uniformes
val nonUniformColumns = result.head() // Récupérer la première ligne des résultats
  .getValuesMap[Long](columns.map(c => s"unique_$c")) // Récupérer les valeurs
  .collect { case (colName, count) if count > 1 => columns.indexOf(colName.stripPrefix("unique_")) } // Filtrer les non-uniformes

// Afficher la liste des index des colonnes non uniformes
println(s"Colonnes non uniformes (index) : ${nonUniformColumns.mkString(", ")}")
